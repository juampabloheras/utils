{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š W&B Data Extraction, Processing, and Excel Export ðŸ“‚\n",
    "\n",
    "#### This notebook contains code to:\n",
    "- Retrieve data from **Weights & Biases** using the API\n",
    "- Perform minimal processing on the data to obtain best metric values and metric values at the epoch where a certain metric is maximized (e.g. Mean Dice)\n",
    "- Export the processed data to **Excel** for further analysis\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ”¬ This cell is where you specify the experiments that you would like to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run name =  UNet-fold1-test3_boxloss_isbi24  id:  kqgjghul\n",
      "run name =  UNet-fold2-test3_boxloss_isbi24  id:  rmugedvf\n",
      "run name =  UNet-fold0-test3_boxloss_isbi24  id:  reupo79e\n",
      "run name =  UNet-fold4-test3_boxloss_isbi24  id:  f5hu42jk\n",
      "run name =  UNet-fold3-test3_boxloss_isbi24  id:  jra6we3x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fold1': 'kqgjghul',\n",
       " 'fold2': 'rmugedvf',\n",
       " 'fold0': 'reupo79e',\n",
       " 'fold4': 'f5hu42jk',\n",
       " 'fold3': 'jra6we3x'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "entity = 'brats_dann'   # Keep the same\n",
    "project = 'Debugging loss codes'  # Your project name\n",
    "experiment_name = 'isbi24'  # text segment to identify experiment\n",
    "\n",
    "runs = api.runs(path=f'{entity}/{project}')\n",
    "\n",
    "run_ids_dict = {}\n",
    "for i in runs:\n",
    "    if experiment_name in i.name:\n",
    "        print(\"run name = \",i.name,\" id: \", i.id)\n",
    "        fold_no = i.name.split('-test')[0].split('-')[-1]\n",
    "        fold_no = 'fold'+ str([part for part in i.name.split('-') if 'fold' in part][0].replace('fold', ''))\n",
    "        run_ids_dict[fold_no] = i.id\n",
    "run_ids_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ“ˆ This cell contains a function that allows you to fetch and plot metrics of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "\n",
    "def fetch_wandb_metrics(entity, project, run_id, horizontal_axis, vertical_axes, show_plots = True):\n",
    "    \"\"\"\n",
    "    Fetch data from Weights and Biases (W&B) and optionally plot multiple vertical axes against a common horizontal axis.\n",
    "    Plots are arranged in rows of 3 columns.\n",
    "\n",
    "    Parameters:\n",
    "    entity (str): W&B entity (username or team).\n",
    "    project (str): W&B project name.\n",
    "    run_id (str): W&B run ID.\n",
    "    horizontal_axis (str): Column to use for the horizontal axis.\n",
    "    vertical_axes (list): List of columns to use for the vertical axes.\n",
    "    show_plots (bool): Whether to show plots\n",
    "\n",
    "    Returns:\n",
    "    results_dict (dict): Dictionary where each key is a vertical axis and the value is the DataFrame of the queried data for that axis.\n",
    "    \"\"\"\n",
    "    # Initialize the W&B API\n",
    "    api = wandb.Api()\n",
    "\n",
    "    run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "\n",
    "    history = run.history(samples=100000)  # Adjust the sample size if needed\n",
    "\n",
    "    columns_to_query = [horizontal_axis] + vertical_axes\n",
    "    available_columns = [col for col in columns_to_query if col in history.columns]\n",
    "\n",
    "    if not available_columns:\n",
    "        print(f\"None of the specified columns were found in the run history: {columns_to_query}\")\n",
    "        return None\n",
    "    \n",
    "    # Query the data for the requested columns\n",
    "    queried_data = history[available_columns]\n",
    "\n",
    "    # Consolidate data by grouping by the horizontal axis and dropping NaN values\n",
    "    consolidated_data = queried_data.groupby(horizontal_axis).agg(\n",
    "        lambda x: x.dropna().iloc[0] if not x.dropna().empty else None\n",
    "    ).reset_index()\n",
    "    queried_data = consolidated_data.dropna(how='all', subset=available_columns[1:])\n",
    "\n",
    "    # Dictionary to hold data for each vertical axis\n",
    "    results_dict = {}\n",
    "    for vertical_axis in vertical_axes:\n",
    "        results_dict[vertical_axis] = queried_data[[horizontal_axis, vertical_axis]].dropna()\n",
    "\n",
    "    # Set plot style\n",
    "    plt.style.use('fivethirtyeight')\n",
    "\n",
    "    # Determine the number of rows and columns for subplots (max 3 columns per row)\n",
    "    num_plots = len(vertical_axes)\n",
    "    num_cols = min(3, num_plots)  # Max 3 columns\n",
    "    num_rows = math.ceil(num_plots / 3)  # Calculate the required number of rows\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(6 * num_cols, 6 * num_rows))\n",
    "\n",
    "    # Handle cases where we have a single row of subplots\n",
    "    if num_plots == 1:\n",
    "        axes = [axes]  # Single plot, make it iterable\n",
    "    elif num_rows == 1:\n",
    "        axes = axes.flatten()  # Flatten if only one row of subplots\n",
    "    else:\n",
    "        axes = axes.flatten()  # Flatten the 2D array of axes for easier iteration\n",
    "\n",
    "    # Plot each vertical axis in its corresponding subplot\n",
    "    for i, vertical_axis in enumerate(vertical_axes):\n",
    "        axes[i].plot(results_dict[vertical_axis][horizontal_axis], results_dict[vertical_axis][vertical_axis], marker='o', linestyle='-', linewidth=2)\n",
    "        axes[i].set_ylabel(vertical_axis, fontsize=14)\n",
    "        axes[i].set_xlabel(horizontal_axis, fontsize=14)\n",
    "        axes[i].grid(True, which='both', linestyle='--', linewidth=0.7)\n",
    "        axes[i].set_title(vertical_axis, fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Hide any unused subplots (if the number of plots is less than the grid size)\n",
    "    for i in range(num_plots, num_rows * num_cols):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    # Display the plot\n",
    "    plt.suptitle(run.name)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    \n",
    "    if not show_plots:\n",
    "        plt.close()\n",
    "\n",
    "    # Return the dictionary containing the queried data\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell to define metrics_dicts. You can show plots by setting show_plots = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "metrics_dicts = {}\n",
    "for fold_no in range(5):\n",
    "    entity = 'brats_dann'\n",
    "    project = 'Debugging loss codes'\n",
    "    # project ='BraTS Goat 5-fold Test'\n",
    "    fold_name = f'fold{fold_no}'\n",
    "    run_id = run_ids_dict[fold_name]\n",
    "    horizontal_axis = 'epoch'\n",
    "    vertical_axes = ['mean_Dice_val', 'mean_HD_val', 'Dice1_val', 'Dice2_val', 'Dice3_val', 'HD1_val', 'HD2_val', 'HD3_val'] \n",
    "    metrics_dicts[fold_name] = fetch_wandb_metrics(entity, project, run_id, horizontal_axis, vertical_axes, show_plots = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function returns the values of all metrics at a specified epoch, optionally saving to an Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_metrics_at_epoch(metrics_dicts, target_epoch, excel_save_dir=None, save_to_excel=True):\n",
    "    data_for_excel = []\n",
    "\n",
    "    # Loop through each fold key in the metrics dictionary\n",
    "    for key, metrics_dfs in metrics_dicts.items():\n",
    "        \n",
    "        # Initialize a dictionary to store metric values for this fold at the target epoch\n",
    "        metric_data = {'Fold': key, 'Epoch': target_epoch}\n",
    "        \n",
    "        # Loop through each metric DataFrame and find the values at the target epoch\n",
    "        for metric_name, df_metric in metrics_dfs.items():\n",
    "            df_metric_filtered = df_metric[df_metric['epoch'] == target_epoch]\n",
    "            if not df_metric_filtered.empty:\n",
    "                metric_row = df_metric_filtered.iloc[0]\n",
    "                metric_data[metric_name] = metric_row[metric_name]\n",
    "            else:\n",
    "                metric_data[metric_name] = None  # If target_epoch is not found in this metric\n",
    "        \n",
    "        # Append the collected data for this fold to the list\n",
    "        data_for_excel.append(metric_data)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df_to_save = pd.DataFrame(data_for_excel)\n",
    "\n",
    "    # Calculate the mean of each metric column, excluding non-numeric columns like 'Fold' and 'Epoch'\n",
    "    average_metrics = df_to_save.drop(columns=['Fold', 'Epoch']).mean().to_dict()\n",
    "    average_metrics['Fold'] = 'Average'\n",
    "    average_metrics['Epoch'] = target_epoch  # Keep the target epoch for reference\n",
    "\n",
    "    # Convert the averages dictionary to a DataFrame and concatenate it with the original DataFrame\n",
    "    average_df = pd.DataFrame([average_metrics])\n",
    "    df_to_save = pd.concat([df_to_save, average_df], ignore_index=True)\n",
    "\n",
    "    # Define default file path if none is provided\n",
    "    if not excel_save_dir:\n",
    "        excel_save_dir = os.getcwd()\n",
    "\n",
    "    excel_file_path = os.path.join(excel_save_dir, f'Metrics_At_Epoch_{target_epoch}.xlsx')\n",
    "\n",
    "    if save_to_excel:\n",
    "        df_to_save.to_excel(excel_file_path, index=False)\n",
    "        print(f\"Data saved to Excel at: {excel_file_path}\")\n",
    "    return df_to_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function will find the epoch where the metric **'max_metric_for_epoch'** is maximized, and return the value of all metrics at this epoch, optionally saving to an Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_metrics_at_max_metric_epoch_for_all_folds(metrics_dicts, epoch_cutoff=100, max_metric_for_epoch='mean_Dice_val', excel_save_dir=None, save_to_excel = True):\n",
    "    data_for_excel = []\n",
    "\n",
    "    # Loop through each fold key in the metrics dictionary\n",
    "    for key, metrics_dfs in metrics_dicts.items():\n",
    "        \n",
    "        # Check if max_metric_for_epoch is present in the DataFrame dictionary\n",
    "        if max_metric_for_epoch in metrics_dfs:\n",
    "            # Filter to only epochs within the cutoff and get the max epoch\n",
    "            df_dice = metrics_dfs[max_metric_for_epoch][metrics_dfs[max_metric_for_epoch]['epoch'] <= epoch_cutoff]\n",
    "            max_dice_index = df_dice[max_metric_for_epoch].idxmax()\n",
    "            max_dice_epoch = df_dice.loc[max_dice_index, 'epoch']\n",
    "\n",
    "            # Use get_metrics_at_epoch to retrieve all metrics at max_dice_epoch for this fold\n",
    "            metrics_at_epoch_df = get_metrics_at_epoch({key: metrics_dfs}, target_epoch=max_dice_epoch, save_to_excel = False)\n",
    "            metrics_data = metrics_at_epoch_df.iloc[0].to_dict()  # Convert row to dictionary\n",
    "\n",
    "            # Set Fold and Max_Epoch for clarity\n",
    "            metrics_data['Fold'] = key\n",
    "            metrics_data['Max_Epoch'] = max_dice_epoch\n",
    "            data_for_excel.append(metrics_data)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df_to_save = pd.DataFrame(data_for_excel)\n",
    "\n",
    "    # Calculate the mean of each metric column, excluding non-numeric columns like 'Fold' and 'Max_Epoch'\n",
    "    average_metrics = df_to_save.drop(columns=['Fold', 'Max_Epoch']).mean().to_dict()\n",
    "    average_metrics['Fold'] = 'Average'\n",
    "    average_metrics['Max_Epoch'] = 'N/A'  # Since averaging epochs doesn't make sense\n",
    "\n",
    "    # Convert the averages dictionary to a DataFrame and concatenate it with the original DataFrame\n",
    "    average_df = pd.DataFrame([average_metrics])\n",
    "    df_to_save = pd.concat([df_to_save, average_df], ignore_index=True)\n",
    "\n",
    "\n",
    "    # Define default file path if none is provided\n",
    "    if not excel_save_dir:\n",
    "        excel_save_dir = os.getcwd()\n",
    "\n",
    "    excel_file_path = os.path.join(excel_save_dir, f'Metrics_At_Max_{max_metric_for_epoch}_Epoch_Upto_{epoch_cutoff}.xlsx')\n",
    "\n",
    "    if save_to_excel:\n",
    "        df_to_save.to_excel(excel_file_path, index=False)\n",
    "\n",
    "    print(f\"Data saved to Excel at: {excel_file_path}\")\n",
    "    return df_to_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function returns the max or min value of all metrics, and saves the results to an Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_max_min_metrics(metrics_dicts, max_names, max_metrics, min_names, min_metrics, epoch_cutoff=75, excel_save_dir='None', save_to_excel = True):\n",
    "    data = []\n",
    "\n",
    "    # Process each fold in the metrics dictionary\n",
    "    for key in metrics_dicts.keys():\n",
    "        # Process metrics that are to be maximized\n",
    "        for idx, metric in enumerate(max_metrics):\n",
    "            df = metrics_dicts[key][metric]\n",
    "            df_limited = df[df['epoch'] < epoch_cutoff]\n",
    "            max_index = df_limited[metric].idxmax()\n",
    "            max_row = df_limited.loc[max_index]\n",
    "            max_value = max_row[metric]\n",
    "            max_epoch = max_row['epoch']\n",
    "            data.append({\n",
    "                'Fold': key,\n",
    "                'Metric Name': max_names[idx],\n",
    "                'Value': max_value,\n",
    "                'Epoch': int(max_epoch),\n",
    "                'Type': 'Max'\n",
    "            })\n",
    "\n",
    "        # Process metrics that are to be minimized\n",
    "        for idx, metric in enumerate(min_metrics):\n",
    "            df = metrics_dicts[key][metric]\n",
    "            df_limited = df[df['epoch'] < epoch_cutoff]\n",
    "            min_index = df_limited[metric].idxmin()\n",
    "            min_row = df_limited.loc[min_index]\n",
    "            min_value = min_row[metric]\n",
    "            min_epoch = min_row['epoch']\n",
    "            data.append({\n",
    "                'Fold': key,\n",
    "                'Metric Name': min_names[idx],\n",
    "                'Value': min_value,\n",
    "                'Epoch': int(min_epoch),\n",
    "                'Type': 'Min'\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    results_df = pd.DataFrame(data)\n",
    "\n",
    "    # Set multi-level index if desired\n",
    "    results_df.set_index(['Fold', 'Metric Name', 'Type'], inplace=True)\n",
    "\n",
    "    # Define default file path if none is provided\n",
    "    if not excel_save_dir:\n",
    "        excel_save_dir = os.getcwd()\n",
    "\n",
    "    excel_file_path = os.path.join(excel_save_dir, f'max_min_metrics.xlsx')\n",
    "\n",
    "    if save_to_excel:\n",
    "        results_df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "    print(f\"Data saved to Excel at: {excel_file_path}\")\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Excel at: /Users/juampablo/Desktop/Kurtlab_A24/isbi_results/Metrics_At_Epoch_99.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>mean_Dice_val</th>\n",
       "      <th>mean_HD_val</th>\n",
       "      <th>Dice1_val</th>\n",
       "      <th>Dice2_val</th>\n",
       "      <th>Dice3_val</th>\n",
       "      <th>HD1_val</th>\n",
       "      <th>HD2_val</th>\n",
       "      <th>HD3_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fold0</td>\n",
       "      <td>99</td>\n",
       "      <td>0.853002</td>\n",
       "      <td>8.977049</td>\n",
       "      <td>0.867547</td>\n",
       "      <td>0.855051</td>\n",
       "      <td>0.836408</td>\n",
       "      <td>9.963797</td>\n",
       "      <td>8.738432</td>\n",
       "      <td>8.228903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fold1</td>\n",
       "      <td>99</td>\n",
       "      <td>0.854783</td>\n",
       "      <td>8.751613</td>\n",
       "      <td>0.865037</td>\n",
       "      <td>0.861902</td>\n",
       "      <td>0.837409</td>\n",
       "      <td>10.220544</td>\n",
       "      <td>8.260969</td>\n",
       "      <td>7.773327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fold2</td>\n",
       "      <td>99</td>\n",
       "      <td>0.855373</td>\n",
       "      <td>9.966650</td>\n",
       "      <td>0.867001</td>\n",
       "      <td>0.858318</td>\n",
       "      <td>0.840801</td>\n",
       "      <td>11.766107</td>\n",
       "      <td>9.484021</td>\n",
       "      <td>8.649774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fold3</td>\n",
       "      <td>99</td>\n",
       "      <td>0.839136</td>\n",
       "      <td>10.862476</td>\n",
       "      <td>0.861933</td>\n",
       "      <td>0.844710</td>\n",
       "      <td>0.810763</td>\n",
       "      <td>12.063130</td>\n",
       "      <td>10.689711</td>\n",
       "      <td>9.834559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fold4</td>\n",
       "      <td>99</td>\n",
       "      <td>0.839929</td>\n",
       "      <td>8.712781</td>\n",
       "      <td>0.855483</td>\n",
       "      <td>0.841862</td>\n",
       "      <td>0.822441</td>\n",
       "      <td>10.358562</td>\n",
       "      <td>8.746573</td>\n",
       "      <td>7.033202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average</td>\n",
       "      <td>99</td>\n",
       "      <td>0.848444</td>\n",
       "      <td>9.454114</td>\n",
       "      <td>0.863400</td>\n",
       "      <td>0.852369</td>\n",
       "      <td>0.829564</td>\n",
       "      <td>10.874428</td>\n",
       "      <td>9.183941</td>\n",
       "      <td>8.303953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fold  Epoch  mean_Dice_val  mean_HD_val  Dice1_val  Dice2_val  \\\n",
       "0    fold0     99       0.853002     8.977049   0.867547   0.855051   \n",
       "1    fold1     99       0.854783     8.751613   0.865037   0.861902   \n",
       "2    fold2     99       0.855373     9.966650   0.867001   0.858318   \n",
       "3    fold3     99       0.839136    10.862476   0.861933   0.844710   \n",
       "4    fold4     99       0.839929     8.712781   0.855483   0.841862   \n",
       "5  Average     99       0.848444     9.454114   0.863400   0.852369   \n",
       "\n",
       "   Dice3_val    HD1_val    HD2_val   HD3_val  \n",
       "0   0.836408   9.963797   8.738432  8.228903  \n",
       "1   0.837409  10.220544   8.260969  7.773327  \n",
       "2   0.840801  11.766107   9.484021  8.649774  \n",
       "3   0.810763  12.063130  10.689711  9.834559  \n",
       "4   0.822441  10.358562   8.746573  7.033202  \n",
       "5   0.829564  10.874428   9.183941  8.303953  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_save_dir = '/Users/juampablo/Desktop/Kurtlab_A24/isbi_results'\n",
    "\n",
    "# Epoch to fetch metrics from\n",
    "target_epoch = 99\n",
    "get_metrics_at_epoch(metrics_dicts=metrics_dicts, excel_save_dir = excel_save_dir, target_epoch=target_epoch)\n",
    "\n",
    "# # Name of metric to maximize\n",
    "# max_metric_for_epoch='mean_Dice_val'\n",
    "# get_metrics_at_max_metric_epoch_for_all_folds(metrics_dicts, epoch_cutoff=100, max_metric_for_epoch=max_metric_for_epoch, excel_save_dir=excel_save_dir)\n",
    "\n",
    "\n",
    "# # Names of metrics to maximize and minimize\n",
    "# max_names = ['max_dice', 'max_dice1', 'max_dice2', 'max_dice3']\n",
    "# max_metrics = ['mean_Dice_val', 'Dice1_val', 'Dice2_val', 'Dice3_val']\n",
    "# min_names = ['min_hd', 'min_hd1', 'min_hd2', 'min_hd3']\n",
    "# min_metrics = ['mean_HD_val', 'HD1_val', 'HD2_val', 'HD3_val']  \n",
    "\n",
    "# get_max_min_metrics(metrics_dicts, max_names, max_metrics, min_names, min_metrics, epoch_cutoff=100, excel_save_dir=excel_save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}